NOTES:

- test stemming vs lemmatization in accuracy
- test vectorization with cleaned vs raw data
- test with different number of features

TODAY:
- test KNN
    - train/test split:
        - test stem vs lemma 
        - test best number of neighbors
    - we
    - lexica
    - find optimal number of neighbors
- Round Robin

STEPS:
- Classifiers
    - SVM
    - bonus: Round Robin
- Visualize results (excel)
- Jupyter Notebook (recheck)
- Test different cases (as stated above)


NOTES FOR JUPYTER NOTEBOOK: 

PREPROCESSING:
- delete duplicate rows
- clean data
- tokenize data
- remove stopwords

DATA CLEANING TECHNIQUES:
- remove extra whitespaces
- make all letters lowercase
- remove @mention
- remove punctuation, numbers, hashtag symbols
- remove HTML encoding

DATA ANALYSIS:
- most frequent words generally (plot + wordcloud)
- most frequent words in positive tweets (plot + wordcloud)
- most frequent words in negative tweets (plot + wordcloud)
- most frequent words in neutral tweets (plot + wordcloud)
- positive, negative, neutral tweets frequency (plots + pie)

STEMMING:
- Use Snowball stemmer because it is Porter 2 stemmer (an improved version of Porter which is widely used)

KNN:
- optimal number of neighbors 10
